
# GPU image. (GpuBuffer)
input_stream: "input_video"

# GPU image. (GpuBuffer)
output_stream: "output_video"

# Throttles the images flowing downstream for flow control. It passes through
# the very first incoming image unaltered, and waits for HandDetectionSubgraph
# downstream in the graph to finish its tasks before it passes through another
# image. All images that come in while waiting are dropped, limiting the number
# of in-flight images in HandDetectionSubgraph to 1. This prevents the nodes in
# HandDetectionSubgraph from queuing up incoming images and data excessively,
# which leads to increased latency and memory usage, unwanted in real-time
# mobile applications. It also eliminates unnecessarily computation, e.g., the
# output produced by a node in the subgraph may get dropped downstream if the
# subsequent nodes are still busy processing previous inputs.
node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:output_video"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# classifies the washing status
node {
  calculator: "IsWashingGpu"
  input_stream: "IMAGE_GPU:throttled_input_video"
  output_stream: "CLASSIFICATIONS:washing_status"
  output_stream: "IMAGE_GPU:cropped_image"
}

#node {
#   calculator: "ScaleImageCalculator"
#   input_stream: "output_video_cpu"
#   output_stream: "output_video_downscaled"
#   node_options {
#     [type.googleapis.com/mediapipe.ScaleImageCalculatorOptions] {
#       target_width: 320
#       target_height: 240
#       preserve_aspect_ratio: true
#       output_format: SRGB
#       algorithm: DEFAULT
#     }
#   }
#}

# Converts classification to drawing primitives for annotation overlay.
node {
  calculator: "LabelsToRenderDataCalculator"
  input_stream: "CLASSIFICATIONS:washing_status"
  output_stream: "RENDER_DATA:washing_status_render_data"
  node_options: {
    [type.googleapis.com/mediapipe.LabelsToRenderDataCalculatorOptions]: {
      color { r: 255 g: 0 b: 0 }
      thickness: 5.0
      font_height_px: 30
      horizontal_offset_px: 30
      vertical_offset_px: 50

      max_num_labels: 1
      location: TOP_LEFT
    }
  }
}

#node {
#   calculator: "ImageCroppingCalculator"
#   input_stream: "IMAGE_GPU:throttled_input_video"
#   output_stream: "IMAGE_GPU:cropped_input_video"
#   options: {
#       [mediapipe.ImageCroppingCalculatorOptions.ext] {
#           norm_width: 1.0
#           norm_height: 0.75
#           norm_center_x: 0.5
#           norm_center_y: 0.5
#           rotation: 1.5707963267948966
#       }
#   }
#}

# Draws annotations and overlays them on top of the input images.
node {
  calculator: "AnnotationOverlayCalculator"
  input_stream: "IMAGE_GPU:throttled_input_video"
#  input_stream: "IMAGE_GPU:cropped_input_video"
  input_stream: "washing_status_render_data"
  output_stream: "IMAGE_GPU:output_video"
}

# Converts GPU buffer to ImageFrame for processing tracking.
node: {
  calculator: "GpuBufferToImageFrameCalculator"
#  input_stream: "output_video"
  input_stream: "cropped_image"
  output_stream: "output_video_cpu"
}
